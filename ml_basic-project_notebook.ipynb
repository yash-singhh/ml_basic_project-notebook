{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afd5e20",
   "metadata": {},
   "source": [
    "# 1. Iris Flower Classification — Multiclass classification basics\n",
    "\n",
    "**Goal:** Train a simple classifier on the Iris dataset and show metrics & a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c73dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iris classification (multiclass) - scikit-learn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred, target_names=iris.target_names))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(iris.target_names)), iris.target_names, rotation=45)\n",
    "plt.yticks(range(len(iris.target_names)), iris.target_names)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e5f43",
   "metadata": {},
   "source": [
    "# 2. House Price Prediction — Regression + feature engineering\n",
    "\n",
    "**Goal:** Use California housing dataset, simple feature engineering, train a RandomForestRegressor and show RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "# Simple feature engineering: add rooms_per_household and population_per_household\n",
    "df['rooms_per_household'] = df['AveRooms'] / (df['HouseAge'] + 1)\n",
    "df['population_per_household'] = df['Population'] / (df['Households'] + 1)\n",
    "X = df.drop(columns=['MedHouseVal'])\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a359d90",
   "metadata": {},
   "source": [
    "# 3. Waiter Tips Prediction — Linear regression on small tabular data\n",
    "\n",
    "**Goal:** Predict tip amount using basic features; use statsmodels for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96891144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "tips = sns.load_dataset('tips')\n",
    "display(tips.head())\n",
    "\n",
    "# Encode categorical variables simply\n",
    "tips['sex'] = tips['sex'].map({'Male':0,'Female':1})\n",
    "tips = pd.get_dummies(tips, columns=['smoker','day','time'], drop_first=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "X = tips.drop(columns=['tip'])\n",
    "y = tips['tip']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, pred, squared=False))\n",
    "\n",
    "# show coefficients\n",
    "coef_df = pd.DataFrame({'feature': X.columns, 'coef': lr.coef_}).sort_values(by='coef', key=abs, ascending=False)\n",
    "display(coef_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28a57c",
   "metadata": {},
   "source": [
    "# 4. Breast Cancer Classification — Binary classification\n",
    "\n",
    "**Goal:** Train a classifier on the breast cancer dataset and show ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "bc = load_breast_cancer(as_frame=True)\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, pred))\n",
    "print('ROC AUC:', roc_auc_score(y_test, pred_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4620eb8",
   "metadata": {},
   "source": [
    "# 5. Student Exam Score Predictor — Simple regression with few features\n",
    "\n",
    "**Goal:** Create a small synthetic dataset of study hours and attendance to predict exam score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f15ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# synthetic data\n",
    "np.random.seed(42)\n",
    "n = 150\n",
    "study_hours = np.random.normal(5, 2, n).clip(0)\n",
    "attendance = (np.random.rand(n) * 20 + 80).clip(60,100)  # percent\n",
    "scores = 50 + 6*study_hours + 0.2*attendance + np.random.normal(0,5,n)\n",
    "\n",
    "df = pd.DataFrame({'study_hours': study_hours, 'attendance': attendance, 'score': scores})\n",
    "display(df.head())\n",
    "\n",
    "X = df[['study_hours','attendance']]\n",
    "y = df['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print('R2:', r2_score(y_test, pred))\n",
    "print('RMSE:', mean_squared_error(y_test, pred, squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e10571",
   "metadata": {},
   "source": [
    "# 6. Diabetes Prediction — Logistic regression\n",
    "\n",
    "**Goal:** Build a binary classifier (logistic regression) on a synthetic 'diabetes' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c2667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=8, n_informative=5, n_redundant=1, weights=[0.6,0.4], random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test, pred))\n",
    "print('ROC AUC:', roc_auc_score(y_test, pred_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265c195",
   "metadata": {},
   "source": [
    "# 7. Handwritten Digit Recognition — First CNN project (simple MLP using sklearn digits)\n",
    "\n",
    "**Goal:** Train a simple classifier on the small digits dataset (8x8 images). For a full MNIST CNN, GPU and longer time are needed; here we keep it lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128,), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "pred = mlp.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dea22",
   "metadata": {},
   "source": [
    "# 8. SMS Spam Detection — NLP + TF-IDF\n",
    "\n",
    "**Goal:** Build a simple spam detector using a tiny sample SMS dataset embedded in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b41b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tiny SMS dataset for demonstration\n",
    "data = [\n",
    " ('ham', \"I'm going to be late, stuck in traffic\"),\n",
    " ('spam', 'WINNER!! You have won a free ticket. Reply CLAIM to get it'),\n",
    " ('ham', 'Can we meet tomorrow?'),\n",
    " ('spam', 'Congratulations, you won $1000! Call now'),\n",
    " ('ham', 'Please send the assignment by tonight'),\n",
    " ('spam', 'URGENT! Your account has been compromised. Click http://fake.link'),\n",
    " ('ham', 'Happy birthday!'),\n",
    " ('spam', 'Free entry in 2 a weekly competition to win FA Cup finals tickets'),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['label','text'])\n",
    "display(df)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "X = vect.fit_transform(df['text'])\n",
    "y = (df['label']=='spam').astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y, test_size=0.3)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9df160",
   "metadata": {},
   "source": [
    "# 9. Salary Prediction — Regression + categorical encoding\n",
    "\n",
    "**Goal:** Create a small synthetic salary dataset including categorical features and train a model with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# small synthetic salary dataset\n",
    "data = [\n",
    " {'title':'Software Engineer','experience':2,'location':'Bengaluru','salary':800000},\n",
    " {'title':'Senior Software Engineer','experience':6,'location':'Bengaluru','salary':1800000},\n",
    " {'title':'Data Scientist','experience':3,'location':'Mumbai','salary':1200000},\n",
    " {'title':'Software Engineer','experience':4,'location':'Mumbai','salary':1100000},\n",
    " {'title':'Manager','experience':8,'location':'Delhi','salary':2000000},\n",
    " {'title':'Data Analyst','experience':1,'location':'Bengaluru','salary':600000},\n",
    " {'title':'Software Engineer','experience':5,'location':'Delhi','salary':1400000},\n",
    " {'title':'Senior Software Engineer','experience':7,'location':'Mumbai','salary':2000000},\n",
    " {'title':'Data Scientist','experience':2,'location':'Delhi','salary':900000},\n",
    " {'title':'Data Analyst','experience':3,'location':'Bengaluru','salary':750000},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = df.drop(columns=['salary'])\n",
    "y = df['salary']\n",
    "\n",
    "cat_cols = ['title','location']\n",
    "preproc = ColumnTransformer([('cat', OneHotEncoder(), cat_cols)], remainder='passthrough')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = make_pipeline(preproc, RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print('MAE:', mean_absolute_error(y_test, pred))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
